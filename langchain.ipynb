{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7EtLHylMFiUvxu4MTijMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mertcan-basut/nlp/blob/main/langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai\n",
        "\n",
        "!pip install -q langchain langchain-openai\n",
        "\n",
        "!pip install -q python-dotenv"
      ],
      "metadata": {
        "id": "wGmNpMwOKna1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0195e33-ce24-4ac5-a7b9-b50d9b8923b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=editthis\" > .env"
      ],
      "metadata": {
        "id": "kZUgLx7JHh6Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "CjpO4-lVFA2z"
      },
      "outputs": [],
      "source": [
        "# a framework for developing LM powered applications\n",
        "from langchain_openai import ChatOpenAI # models\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate # input prompts\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain.output_parsers import StructuredOutputParser # output parsers\n",
        "from langchain.output_parsers import ResponseSchema\n",
        "\n",
        "import openai # direct API calls to OpenAI\n",
        "\n",
        "import json\n",
        "import os\n",
        "# https://platform.openai.com/api-keys\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\\\n",
        "This leaf blower is pretty amazing.  It has four settings: \\\n",
        "candle blower, gentle breeze, windy city, and tornado. \\\n",
        "It arrived in two days, just in time for my wife's \\\n",
        "anniversary present. \\\n",
        "I think my wife liked it so much she was speechless. \\\n",
        "So far I've been the only one using it, and I've been \\\n",
        "using it every other morning to clear the leaves on our lawn. \\\n",
        "It's slightly more expensive than the other leaf blowers \\\n",
        "out there, but I think it's worth it for the extra features.\\\n",
        "\"\"\"\n",
        "\n",
        "system_message_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
        "\"\"\"\n",
        "\n",
        "human_message_template = \"\"\"\\\n",
        "text: {text}\n",
        "\"\"\"\n",
        "\n",
        "format_instructions_template = \"\"\"\\\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CuOOgUWy00AI"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "get_completion(\"Hi!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ez7AjgGLJ7jq",
        "outputId": "00398d69-ff06-48f4-845e-66a396d9113b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prompt(system_message, human_message, format_instructions):\n",
        "  return f\"\"\"\\\n",
        "{system_message}\n",
        "\n",
        "{human_message}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "system_message_prompt = system_message_template.format()\n",
        "human_message_prompt = human_message_template.format(text=text)\n",
        "format_instructions_prompt = format_instructions_template.format()\n",
        "prompt = format_prompt(system_message_prompt, human_message_prompt, format_instructions_prompt)\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srwP4Vv99JSI",
        "outputId": "ef3c3065-bde7-464f-9ac3-faa85cefee16"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the following text, extract the following information:\n",
            "\n",
            "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
            "\n",
            "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
            "\n",
            "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
            "\n",
            "\n",
            "text: This leaf blower is pretty amazing.  It has four settings: candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
            "\n",
            "\n",
            "Format the output as JSON with the following keys:\n",
            "gift\n",
            "delivery_days\n",
            "price_value\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(prompt)\n",
        "print(response)\n",
        "\n",
        "output_dict = json.loads(response)\n",
        "output_dict.get('delivery_days')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlXK5Ub0BNOD",
        "outputId": "9e7dc2ef-6603-45a6-fd90-de7de3897ed0"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"gift\": true,\n",
            "  \"delivery_days\": 2,\n",
            "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there\"]\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
        "\n",
        "chat([HumanMessage(content=\"Hi!\")]).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qlSD8PcbwgSN",
        "outputId": "a73b6afd-0cc9-457e-e3f1-39506162dc02"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_message_template)\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_message_template)\n",
        "\n",
        "gift_schema = ResponseSchema(name=\"gift\", description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\")\n",
        "delivery_days_schema = ResponseSchema(name=\"delivery_days\", description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\")\n",
        "price_value_schema = ResponseSchema(name=\"price_value\", description=\"Extract any sentences about the value or price, and output them as a comma separated Python list.\")\n",
        "response_schemas = [gift_schema, delivery_days_schema, price_value_schema]\n",
        "\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "format_instructions_prompt = SystemMessage(content=format_instructions)\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt, format_instructions_prompt])\n",
        "prompt = prompt_template.format_messages(text=text)\n",
        "for message in prompt: print(message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-m-vJjDA5ZA",
        "outputId": "aa155e13-0b14-4294-aa19-7c788e054f82"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the following text, extract the following information:\n",
            "\n",
            "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
            "\n",
            "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
            "\n",
            "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
            "\n",
            "text: This leaf blower is pretty amazing.  It has four settings: candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
            "\n",
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"gift\": string  // Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
            "\t\"delivery_days\": string  // How many days did it take for the product to arrive? If this information is not found, output -1.\n",
            "\t\"price_value\": string  // Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat(prompt).content\n",
        "print(response)\n",
        "\n",
        "output_dict = output_parser.parse(response)\n",
        "output_dict.get('delivery_days')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3gB1eU40xo2",
        "outputId": "6c69f3cd-fd26-4871-9a99-f01b35a2ad7a"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "\t\"gift\": true,\n",
            "\t\"delivery_days\": 2,\n",
            "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
            "}\n",
            "```\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    }
  ]
}